{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First image-description dataset consists on 10 descriptions for 56 Genshin Impact characters.\n",
    "We select central pose and 9 random images for each character.\n",
    "\n",
    "Therefore, in total, the dataset will have 560 with 10 descriptions each, resulting in 5600 samples.\n",
    "\n",
    "\n",
    "In order to obtain this dataset, we first cropped some images manually (reference).\n",
    "\n",
    "We search which would be a similar cropping for the other images using CLIP, comparing CLIP features with those from the reference image of the same character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crisan/miniconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpath = 'genshin_dataset'\n",
    "original_ims = os.path.join(mpath, 'character_imgs')\n",
    "dataset_path = os.path.join(mpath, 'dataset1')\n",
    "#os.makedirs(dataset_path, exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "candidate_preprocess = Compose([\n",
    "        _convert_image_to_rgb,\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "\n",
    "CROP_RES = 256\n",
    "THRESHOLD = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_crops(image_tensor, crop_res, overlap=0.25):\n",
    "    h, w = img.shape[2:]\n",
    "    #print(h, w)\n",
    "    num_h = h // crop_res\n",
    "    num_w = w // crop_res\n",
    "    #print(num_h, num_w)\n",
    "\n",
    "    # Calculate the stride\n",
    "    stride = int(crop_res * (1 - overlap))\n",
    "\n",
    "    # Calculate the number of crops along each dimension\n",
    "    n_crops_y = (image_tensor.size(2) - crop_res) // stride + 1\n",
    "    n_crops_x = (image_tensor.size(3) - crop_res) // stride + 1\n",
    "\n",
    "    # Collect crops\n",
    "    crops, centers = [], []\n",
    "    for y in range(n_crops_y):\n",
    "        for x in range(n_crops_x):\n",
    "            start_y = y * stride\n",
    "            start_x = x * stride\n",
    "            crop = image_tensor[:, :, start_y:start_y + crop_res, start_x:start_x + crop_res]\n",
    "            crops.append(crop)\n",
    "            centers.append((start_y + crop_res//2, start_x + crop_res//2))\n",
    "\n",
    "    # Convert to tensor containing all crops\n",
    "    crops_tensor = torch.stack(crops)\n",
    "\n",
    "    #print(f'Generated {crops_tensor.size(0)} crops of size {crop_res}x{crop_res}')\n",
    "    return crops_tensor, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winners(ref_features, crops, thres=THRESHOLD):\n",
    "    winners = []\n",
    "    ccrop_fn = CenterCrop(224)\n",
    "    num_crops = crops.shape[0]\n",
    "    with torch.no_grad():\n",
    "        #ref_features = model.encode_image(crop_ref)\n",
    "        for n in range(num_crops):\n",
    "            cand_features = model.encode_image(ccrop_fn(crops[n]))\n",
    "            #print(ref_features.shape, cand_features.shape)\n",
    "            sim = F.normalize(ref_features, dim=-1) @ F.normalize(cand_features, dim=-1).T\n",
    "            #print(sim.item())\n",
    "            if sim >= thres:\n",
    "                #print(f'Winner sim with {sim}')\n",
    "                winners.append((sim, crops[n].squeeze(0), n))\n",
    "        #print(f'Got {len(winners)} winners')\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No winners for xinyan, image genshin_dataset/character_imgs/xinyan/Captura de pantalla (699).png\n",
      "No winners for sayu, image genshin_dataset/character_imgs/sayu/Captura de pantalla (493).png\n",
      "No winners for kaeya, image genshin_dataset/character_imgs/kaeya/Captura de pantalla (1187).png\n",
      "5570\n"
     ]
    }
   ],
   "source": [
    "ref_path = os.path.join(mpath, 'face_crop')\n",
    "df = pd.read_csv(os.path.join(mpath, 'face_crop_256.csv'))\n",
    "\n",
    "CROP_SIZE = 400\n",
    "\n",
    "train_dict = {}\n",
    "ii=0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    character = row[\"character\"]\n",
    "    crop_ref = preprocess(Image.open(os.path.join(ref_path, row['cropped_img_256']))).unsqueeze(0).to(device)\n",
    "    \n",
    "    character_ims = [f for f in os.listdir(os.path.join(original_ims, character)) if 'zero' not in f and 'ood' not in f]\n",
    "    character_ims = random.sample(character_ims, 9) + ['zero.png']\n",
    "\n",
    "    for i_f, f in enumerate(character_ims):\n",
    "        im_path = os.path.join(dataset_path, f\"{character}_{i_f}.png\")\n",
    "        orig_im_path = os.path.join(original_ims, character, f)\n",
    "        if not os.path.exists(im_path):\n",
    "            oimg = Image.open(orig_im_path)\n",
    "            img = candidate_preprocess(oimg).unsqueeze(0).to(device)\n",
    "            \n",
    "            crops, centers = generate_crops(img, CROP_RES, overlap=0.75)\n",
    "            with torch.no_grad():\n",
    "                ref_features = model.encode_image(crop_ref)\n",
    "            winners = get_winners(ref_features, crops)\n",
    "            winners = sorted(winners, reverse=True)\n",
    "            try:\n",
    "                ### Winner:\n",
    "                win_crop = winners[0]\n",
    "                win_center = centers[win_crop[2]]\n",
    "                left = win_center[1] - CROP_SIZE//2\n",
    "                right = left + CROP_SIZE\n",
    "                top = win_center[0] - CROP_SIZE//2\n",
    "                bottom = top + CROP_SIZE\n",
    "                ## cropped image ##\n",
    "                im1 = oimg.crop((left, top, right, bottom))\n",
    "                \n",
    "                im1.save(im_path)\n",
    "            except:\n",
    "                print(f\"No winners for {character}, image {orig_im_path}\")\n",
    "                continue\n",
    "        if os.path.exists(im_path):\n",
    "            for desc in range(10):\n",
    "                train_dict[ii] = [character, im_path, orig_im_path, row[f\"desc{desc}\"]]\n",
    "                ii+=1\n",
    "    \n",
    "print(len(train_dict.keys()))\n",
    "train_df = pd.DataFrame.from_dict(train_dict, orient='index', columns=['character', 'im_path', 'orig_path', 'description',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>im_path</th>\n",
       "      <th>orig_path</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A young woman with light blonde hair tied in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A character with blonde hair, dressed in a red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A woman with light blonde hair tied in a ponyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A character with blonde hair, dressed in a red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A young woman with blonde hair tied in a high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A mysterious female character with short blue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A blue-haired character with large purple eyes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A girl with pastel blue hair in soft waves, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A young woman with ethereal blue hair and lumi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A character with light blue, curly hair, accen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5570 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     character                                 im_path  \\\n",
       "0      yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "1      yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "2      yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "3      yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "4      yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "...        ...                                     ...   \n",
       "5565     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "5566     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "5567     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "5568     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "5569     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "\n",
       "                                              orig_path  \\\n",
       "0     genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "1     genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "2     genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "3     genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "4     genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "...                                                 ...   \n",
       "5565      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "5566      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "5567      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "5568      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "5569      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "\n",
       "                                            description  \n",
       "0     A young woman with light blonde hair tied in a...  \n",
       "1     A character with blonde hair, dressed in a red...  \n",
       "2     A woman with light blonde hair tied in a ponyt...  \n",
       "3     A character with blonde hair, dressed in a red...  \n",
       "4     A young woman with blonde hair tied in a high ...  \n",
       "...                                                 ...  \n",
       "5565  A mysterious female character with short blue ...  \n",
       "5566  A blue-haired character with large purple eyes...  \n",
       "5567  A girl with pastel blue hair in soft waves, re...  \n",
       "5568  A young woman with ethereal blue hair and lumi...  \n",
       "5569  A character with light blue, curly hair, accen...  \n",
       "\n",
       "[5570 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(mpath, 'dataset1.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
