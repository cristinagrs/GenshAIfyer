{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import CLIPTokenizer, PretrainedConfig, T5TokenizerFast\n",
    "from transformers import CLIPTextModelWithProjection, T5EncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>im_path</th>\n",
       "      <th>orig_path</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A young woman with light blonde hair tied in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A character with blonde hair, dressed in a red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A woman with light blonde hair tied in a ponyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A character with blonde hair, dressed in a red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A young woman with blonde hair tied in a high ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character                                 im_path  \\\n",
       "0   yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "1   yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "2   yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "3   yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "4   yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "\n",
       "                                           orig_path  \\\n",
       "0  genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "1  genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "2  genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "3  genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "4  genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "\n",
       "                                         description  \n",
       "0  A young woman with light blonde hair tied in a...  \n",
       "1  A character with blonde hair, dressed in a red...  \n",
       "2  A woman with light blonde hair tied in a ponyt...  \n",
       "3  A character with blonde hair, dressed in a red...  \n",
       "4  A young woman with blonde hair tied in a high ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = 'genshin_dataset'\n",
    "images_path = os.path.join(dataset_path, 'dataset1')\n",
    "prompt_embbedings_path = os.path.join(dataset_path, 'dataset1_prompt_embbedings_sd3')\n",
    "#os.mkdir(prompt_embbedings_path)\n",
    "train_df = pd.read_csv(os.path.join(dataset_path, 'dataset1.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5570\n",
      "11140\n"
     ]
    }
   ],
   "source": [
    "## Duplicate rows adding \"genshin style to the prompts\" ##\n",
    "new_data = []\n",
    "columns = list(train_df.columns)\n",
    "print(len(train_df))\n",
    "for idx, row in train_df.iterrows():\n",
    "    clist = []\n",
    "    for c in columns:\n",
    "        val = row[c]\n",
    "        if c == 'description': val += ' Genshin style.'\n",
    "        clist.append(val)\n",
    "    new_data.append(clist)\n",
    "\n",
    "df2 = pd.DataFrame(new_data, columns=columns) \n",
    "train_df = pd.concat([train_df, df2], ignore_index=True)\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prompts:  1102\n"
     ]
    }
   ],
   "source": [
    "prompts = train_df['description'].unique()\n",
    "print('Number of prompts: ', len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee02c7f6d27f4dedb86a949c8d874b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440fcb85227e44cfb2dfabe65c7afdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model = \"stabilityai/stable-diffusion-3-medium-diffusers\"\n",
    "weight_dtype = torch.float16\n",
    "\n",
    "# Load the tokenizers\n",
    "tokenizer_one = CLIPTokenizer.from_pretrained(pretrained_model, subfolder=\"tokenizer\")\n",
    "tokenizer_two = CLIPTokenizer.from_pretrained(pretrained_model, subfolder=\"tokenizer_2\")\n",
    "tokenizer_three = T5TokenizerFast.from_pretrained(pretrained_model, subfolder=\"tokenizer_3\")\n",
    "tokenizers = [tokenizer_one, tokenizer_two, tokenizer_three]\n",
    "\n",
    "\n",
    "# Load text encoders\n",
    "text_encoder_one = CLIPTextModelWithProjection.from_pretrained(pretrained_model, subfolder=\"text_encoder\")\n",
    "text_encoder_two = CLIPTextModelWithProjection.from_pretrained(pretrained_model, subfolder=\"text_encoder_2\")\n",
    "text_encoder_three = T5EncoderModel.from_pretrained(pretrained_model, subfolder=\"text_encoder_3\")\n",
    "text_encoder_one.requires_grad_(False)\n",
    "text_encoder_two.requires_grad_(False)\n",
    "text_encoder_three.requires_grad_(False)\n",
    "text_encoder_one.to(\"cuda\", dtype=weight_dtype)\n",
    "text_encoder_two.to(\"cuda\", dtype=weight_dtype)\n",
    "text_encoder_three.to(\"cuda\", dtype=weight_dtype)\n",
    "text_encoders = [text_encoder_one, text_encoder_two, text_encoder_three]\n",
    "\n",
    "max_sequence_length = 77 # seq len from stable-diffusion-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to get embeddings from prompts (from hugging face codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_prompt_with_clip(text_encoder, tokenizer, prompt: str, device=None,  text_input_ids=None, num_images_per_prompt: int = 1,):\n",
    "    prompt = [prompt] if isinstance(prompt, str) else prompt\n",
    "    batch_size = len(prompt)\n",
    "\n",
    "    text_inputs = tokenizer(prompt, padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\",)\n",
    "    text_input_ids = text_inputs.input_ids\n",
    "\n",
    "    prompt_embeds = text_encoder(text_input_ids.to(device), output_hidden_states=True)\n",
    "\n",
    "    pooled_prompt_embeds = prompt_embeds[0]\n",
    "    prompt_embeds = prompt_embeds.hidden_states[-2]\n",
    "    prompt_embeds = prompt_embeds.to(dtype=text_encoder.dtype, device=device)\n",
    "\n",
    "    _, seq_len, _ = prompt_embeds.shape\n",
    "    # duplicate text embeddings for each generation per prompt, using mps friendly method\n",
    "    prompt_embeds = prompt_embeds.repeat(1, num_images_per_prompt, 1)\n",
    "    prompt_embeds = prompt_embeds.view(batch_size * num_images_per_prompt, seq_len, -1)\n",
    "    return prompt_embeds, pooled_prompt_embeds\n",
    "\n",
    "def _encode_prompt_with_t5(text_encoder, tokenizer, max_sequence_length, prompt=None, num_images_per_prompt=1, device=None, text_input_ids=None):\n",
    "    prompt = [prompt] if isinstance(prompt, str) else prompt\n",
    "    batch_size = len(prompt)\n",
    "\n",
    "    text_inputs = tokenizer(prompt, padding=\"max_length\", max_length=max_sequence_length, truncation=True, add_special_tokens=True, return_tensors=\"pt\",)\n",
    "    text_input_ids = text_inputs.input_ids\n",
    "\n",
    "    prompt_embeds = text_encoder(text_input_ids.to(device))[0]\n",
    "\n",
    "    dtype = text_encoder.dtype\n",
    "    prompt_embeds = prompt_embeds.to(dtype=dtype, device=device)\n",
    "\n",
    "    _, seq_len, _ = prompt_embeds.shape\n",
    "\n",
    "    # duplicate text embeddings and attention mask for each generation per prompt, using mps friendly method\n",
    "    prompt_embeds = prompt_embeds.repeat(1, num_images_per_prompt, 1)\n",
    "    prompt_embeds = prompt_embeds.view(batch_size * num_images_per_prompt, seq_len, -1)\n",
    "    return prompt_embeds\n",
    "\n",
    "def encode_prompt(text_encoders, tokenizers, prompt,  max_sequence_length,  device=None,  num_images_per_prompt: int = 1,\n",
    "                  text_input_ids_list=None,):\n",
    "    prompt = [prompt] if isinstance(prompt, str) else prompt\n",
    "\n",
    "    clip_tokenizers = tokenizers[:2]\n",
    "    clip_text_encoders = text_encoders[:2]\n",
    "\n",
    "    clip_prompt_embeds_list = []\n",
    "    clip_pooled_prompt_embeds_list = []\n",
    "    for i, (tokenizer, text_encoder) in enumerate(zip(clip_tokenizers, clip_text_encoders)):\n",
    "        prompt_embeds, pooled_prompt_embeds = _encode_prompt_with_clip(\n",
    "            text_encoder=text_encoder,\n",
    "            tokenizer=tokenizer,\n",
    "            prompt=prompt,\n",
    "            device=device if device is not None else text_encoder.device,\n",
    "            num_images_per_prompt=num_images_per_prompt,\n",
    "            text_input_ids=text_input_ids_list[i] if text_input_ids_list else None,\n",
    "        )\n",
    "        clip_prompt_embeds_list.append(prompt_embeds)\n",
    "        clip_pooled_prompt_embeds_list.append(pooled_prompt_embeds)\n",
    "\n",
    "    clip_prompt_embeds = torch.cat(clip_prompt_embeds_list, dim=-1)\n",
    "    pooled_prompt_embeds = torch.cat(clip_pooled_prompt_embeds_list, dim=-1)\n",
    "\n",
    "    t5_prompt_embed = _encode_prompt_with_t5(\n",
    "        text_encoders[-1],\n",
    "        tokenizers[-1],\n",
    "        max_sequence_length,\n",
    "        prompt=prompt,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        text_input_ids=text_input_ids_list[-1] if text_input_ids_list else None,\n",
    "        device=device if device is not None else text_encoders[-1].device,\n",
    "    )\n",
    "\n",
    "    clip_prompt_embeds = torch.nn.functional.pad(\n",
    "        clip_prompt_embeds, (0, t5_prompt_embed.shape[-1] - clip_prompt_embeds.shape[-1])\n",
    "    )\n",
    "    prompt_embeds = torch.cat([clip_prompt_embeds, t5_prompt_embed], dim=-2)\n",
    "\n",
    "    return prompt_embeds, pooled_prompt_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Embeddings for each prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate embeddings for each prompt and save them\n",
    "for idx, prompt in enumerate(prompts):\n",
    "    # generate embeddings:\n",
    "    with torch.no_grad():\n",
    "        prompt_embeds, pooled_prompt_embeds = encode_prompt(\n",
    "            text_encoders, tokenizers, prompt, max_sequence_length\n",
    "        )\n",
    "        # delete batch dimension\n",
    "        prompt_embeds = torch.squeeze(prompt_embeds.to(\"cpu\"), 0)\n",
    "        pooled_prompt_embeds = torch.squeeze(pooled_prompt_embeds.to(\"cpu\"), 0)\n",
    "\n",
    "        # save embeddings\n",
    "        emb_path = os.path.join(prompt_embbedings_path, f\"emb{idx}.pt\")\n",
    "        pooled_emb_path = os.path.join(prompt_embbedings_path, f\"pooled_emb{idx}.pt\")\n",
    "        torch.save(prompt_embeds, emb_path)\n",
    "        torch.save(pooled_prompt_embeds, pooled_emb_path)\n",
    "\n",
    "        # update all rows in train_df to find path\n",
    "        train_df.loc[ train_df['description']==prompt, 'embeddings'] = emb_path\n",
    "        train_df.loc[ train_df['description']==prompt, 'pooled_embeddings'] = pooled_emb_path\n",
    "train_df.to_csv(os.path.join(dataset_path, 'dataset1_sd3_emb2.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>im_path</th>\n",
       "      <th>orig_path</th>\n",
       "      <th>description</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>pooled_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A young woman with light blonde hair tied in a...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A character with blonde hair, dressed in a red...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A woman with light blonde hair tied in a ponyt...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A character with blonde hair, dressed in a red...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yoimiya</td>\n",
       "      <td>genshin_dataset/dataset1/yoimiya_0.png</td>\n",
       "      <td>genshin_dataset/character_imgs/yoimiya/Captura...</td>\n",
       "      <td>A young woman with blonde hair tied in a high ...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11135</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A mysterious female character with short blue ...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11136</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A blue-haired character with large purple eyes...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A girl with pastel blue hair in soft waves, re...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11138</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A young woman with ethereal blue hair and lumi...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>ganyu</td>\n",
       "      <td>genshin_dataset/dataset1/ganyu_9.png</td>\n",
       "      <td>genshin_dataset/character_imgs/ganyu/zero.png</td>\n",
       "      <td>A character with light blue, curly hair, accen...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "      <td>genshin_dataset/dataset1_prompt_embbedings_sd3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11140 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      character                                 im_path  \\\n",
       "0       yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "1       yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "2       yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "3       yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "4       yoimiya  genshin_dataset/dataset1/yoimiya_0.png   \n",
       "...         ...                                     ...   \n",
       "11135     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "11136     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "11137     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "11138     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "11139     ganyu    genshin_dataset/dataset1/ganyu_9.png   \n",
       "\n",
       "                                               orig_path  \\\n",
       "0      genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "1      genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "2      genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "3      genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "4      genshin_dataset/character_imgs/yoimiya/Captura...   \n",
       "...                                                  ...   \n",
       "11135      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "11136      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "11137      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "11138      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "11139      genshin_dataset/character_imgs/ganyu/zero.png   \n",
       "\n",
       "                                             description  \\\n",
       "0      A young woman with light blonde hair tied in a...   \n",
       "1      A character with blonde hair, dressed in a red...   \n",
       "2      A woman with light blonde hair tied in a ponyt...   \n",
       "3      A character with blonde hair, dressed in a red...   \n",
       "4      A young woman with blonde hair tied in a high ...   \n",
       "...                                                  ...   \n",
       "11135  A mysterious female character with short blue ...   \n",
       "11136  A blue-haired character with large purple eyes...   \n",
       "11137  A girl with pastel blue hair in soft waves, re...   \n",
       "11138  A young woman with ethereal blue hair and lumi...   \n",
       "11139  A character with light blue, curly hair, accen...   \n",
       "\n",
       "                                              embeddings  \\\n",
       "0      genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "1      genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "2      genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "3      genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "4      genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "...                                                  ...   \n",
       "11135  genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "11136  genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "11137  genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "11138  genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "11139  genshin_dataset/dataset1_prompt_embbedings_sd3...   \n",
       "\n",
       "                                       pooled_embeddings  \n",
       "0      genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "1      genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "2      genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "3      genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "4      genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "...                                                  ...  \n",
       "11135  genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "11136  genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "11137  genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "11138  genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "11139  genshin_dataset/dataset1_prompt_embbedings_sd3...  \n",
       "\n",
       "[11140 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dif_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
